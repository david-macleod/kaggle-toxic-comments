{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving M000 by changing MultinomialNB hyperparameters / vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from __future__ import division, print_function \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import binarize \n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from evaluation import cross_validate_multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes and load test/train data, some input text is \"N/A\" so turn na_filter off to prevent this being converted to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_classes = [\n",
    "    'toxic', 'severe_toxic', 'obscene', \n",
    "    'threat', 'insult', 'identity_hate' \n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', na_filter=False)\n",
    "X_train_text = df['comment_text'].values\n",
    "Y_train = df[toxic_classes].values\n",
    "id_train = df['id']\n",
    "\n",
    "#df = pd.read_csv('../data/test.csv', na_filter=False)\n",
    "#X_test_text = df['comment_text'].values\n",
    "#id_test = df['id']\n",
    "\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will first test variations of vectorizing our data, then later refine the hyperparameters.\n",
    "\n",
    "A grid search would be preferable but vectorization is slow (and GridSearchCV does not give us the flexibility we require for our evaluation metric) so will test parameters separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: N-grams\n",
    "Test bigrams and trigrams (pairs/triples of consecutive tokens) as features\n",
    "\n",
    "Including multiple tokens as features will hopefully capture context/sentiment to a some extent, and can build features which will not be important as unigrams e.g. \"back off\" may be more discriminative than \"back\" and \"off\" individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e33a879f1eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ngrams:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'| mean_cv_log_loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'| std_cv_log_loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'| feature_count:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "for ngram in (1, ):\n",
    "    cvec = CountVectorizer(min_df=5, stop_words='english', ngram_range=(1, ngram))\n",
    "    X_train = cvec.fit_transform(X_train_text)\n",
    "    cv_scores = cross_validate_multilabel(MultinomialNB(), X_train, Y_train, cv=10, scoring='neg_log_loss')\n",
    "    print('ngrams:', ngram, '| mean_cv_log_loss:', np.mean(cv_scores),'| std_cv_log_loss:', np.std(cv_scores), '| feature_count:', len(cvec.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Minimum document frequency\n",
    "Remove tokens that occur in only a few documents as these will have a less reliable class conditional probability, and will reduce the model dimensions\n",
    "\n",
    "Document frequency represented as count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1 | mean_cv_log_loss: -0.266987208636 | std_cv_log_loss: 0.0126325177531\n",
      "min_df: 10 | mean_cv_log_loss: -0.184881697959 | std_cv_log_loss: 0.00619859556429\n",
      "min_df: 100 | mean_cv_log_loss: -0.167841838394 | std_cv_log_loss: 0.00414391225583\n",
      "min_df: 1000 | mean_cv_log_loss: -0.145054925509 | std_cv_log_loss: 0.00376654461346\n",
      "min_df: 10000 | mean_cv_log_loss: -0.148005643878 | std_cv_log_loss: 0.00284898122089\n",
      "min_df: 15000 | mean_cv_log_loss: -0.148241637146 | std_cv_log_loss: 0.0023213639865\n"
     ]
    }
   ],
   "source": [
    "for df in (1, 10, 100, 1000, 10000, 15000):\n",
    "    cvec = CountVectorizer(min_df=df, stop_words='english')\n",
    "    X_train = cvec.fit_transform(X_train_text)\n",
    "    cv_scores = cross_validate_multilabel(MultinomialNB(), X_train, Y_train, cv=10, scoring='neg_log_loss')\n",
    "    print('min_df:', df, '| mean_cv_log_loss:', np.mean(cv_scores),'| std_cv_log_loss:', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Maximum document frequency\n",
    "Remove tokens that occur in most documents (that are not already stop words) as these may can be less discriminative, and will reduce the model dimensions.\n",
    "\n",
    "Document frequency represented as a proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df: 0.25 | mean_cv_log_loss: -0.148005643878 | std_cv_log_loss: 0.00284898122089\n",
      "max_df: 0.2 | mean_cv_log_loss: -0.146071161582 | std_cv_log_loss: 0.0019049370355\n",
      "max_df: 0.15 | mean_cv_log_loss: -0.142655204835 | std_cv_log_loss: 0.000939114055779\n"
     ]
    }
   ],
   "source": [
    "for df in (0.25, 0.2, 0.15):\n",
    "    cvec = CountVectorizer(min_df=10000, max_df=df, stop_words='english')\n",
    "    X_train = cvec.fit_transform(X_train_text)\n",
    "    cv_scores = cross_validate_multilabel(MultinomialNB(), X_train, Y_train, cv=10, scoring='neg_log_loss')\n",
    "    print('max_df:', df, '| mean_cv_log_loss:', np.mean(cv_scores),'| std_cv_log_loss:', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Chi2 feature selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting models on all data, then applying to test data to give us our probabilities for submission\n",
    "\n",
    "We use OneVsRestClassifier to fit one model per class as MultinomialNB cannot handle a multi-label input by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "ovr_nb = OneVsRestClassifier(nb_model)\n",
    "ovr_nb.fit(X_train, Y_train) \n",
    "ovr_nb.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.52842777e-05,   1.52804881e-10,   1.26619762e-05,\n",
       "          2.38209407e-10,   3.36363407e-06,   3.01831396e-08],\n",
       "       [  6.66552593e-16,   3.46862042e-30,   3.85420157e-18,\n",
       "          5.95280927e-22,   6.38911831e-20,   9.44841693e-21],\n",
       "       [  5.13770247e-19,   1.04641141e-42,   9.34651433e-23,\n",
       "          1.00644397e-41,   7.25965785e-23,   6.35388326e-38],\n",
       "       ..., \n",
       "       [  3.06263881e-06,   5.02402659e-11,   9.02998535e-07,\n",
       "          2.34925660e-11,   5.77075874e-07,   1.24178475e-09],\n",
       "       [  1.64277107e-02,   1.97501507e-02,   2.54775188e-02,\n",
       "          2.17313876e-02,   2.30510110e-02,   3.94433234e-02],\n",
       "       [  1.78417474e-21,   8.62141034e-55,   2.28563059e-26,\n",
       "          4.45122550e-60,   3.05508745e-29,   4.89934988e-51]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_prob = ovr_nb.predict_proba(X_test)\n",
    "Y_test_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that predict_proba function returns the normalised probabilities over each one-vs-rest class distribution.\n",
    "\n",
    "In other words, we don't use the raw \"posterior\" probability calculated by the MultinomialNB `P(x|y)•P(y)`  as these values will be very small, and is not a realistic probability anyway as this does not include the \"evidence\" term P(x) in the Bayes equation as this is fixed for all classes. Instead this value is normalised so that the \"probabilities\" for each record sum to ~1 within each binary class decision. So the probability `P(yi|Xi) + P(not(yi)|Xi) ≈ 1`.\n",
    "\n",
    "Note that as this is a multilabel classification for the one-vs-rest estimator the probability  is normalised within each class, and not across _all_ classes, so the sum of all probabilities across all classes does not have to sum to 1. For example we can have `P(y1|xi) = P(y2|xi) ≈ 1`  etc which gives us a high probability of that record belonging to multiple classes. Equally it is valid for the probability of a record to have low probabilities across all classes, suggesting it does not belong to any of the classes (we have many training examples that exhibit this characteristic). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>2.528428e-05</td>\n",
       "      <td>1.528049e-10</td>\n",
       "      <td>1.266198e-05</td>\n",
       "      <td>2.382094e-10</td>\n",
       "      <td>3.363634e-06</td>\n",
       "      <td>3.018314e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>6.665526e-16</td>\n",
       "      <td>3.468620e-30</td>\n",
       "      <td>3.854202e-18</td>\n",
       "      <td>5.952809e-22</td>\n",
       "      <td>6.389118e-20</td>\n",
       "      <td>9.448417e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>5.137702e-19</td>\n",
       "      <td>1.046411e-42</td>\n",
       "      <td>9.346514e-23</td>\n",
       "      <td>1.006444e-41</td>\n",
       "      <td>7.259658e-23</td>\n",
       "      <td>6.353883e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>6.786617e-03</td>\n",
       "      <td>1.692325e-05</td>\n",
       "      <td>1.369010e-03</td>\n",
       "      <td>6.565989e-05</td>\n",
       "      <td>7.297767e-04</td>\n",
       "      <td>5.367645e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>2.723515e-02</td>\n",
       "      <td>4.956793e-03</td>\n",
       "      <td>2.108912e-02</td>\n",
       "      <td>4.873167e-03</td>\n",
       "      <td>1.588704e-02</td>\n",
       "      <td>1.861962e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         toxic  severe_toxic       obscene        threat  \\\n",
       "0   6044863  2.528428e-05  1.528049e-10  1.266198e-05  2.382094e-10   \n",
       "1   6102620  6.665526e-16  3.468620e-30  3.854202e-18  5.952809e-22   \n",
       "2  14563293  5.137702e-19  1.046411e-42  9.346514e-23  1.006444e-41   \n",
       "3  21086297  6.786617e-03  1.692325e-05  1.369010e-03  6.565989e-05   \n",
       "4  22982444  2.723515e-02  4.956793e-03  2.108912e-02  4.873167e-03   \n",
       "\n",
       "         insult  identity_hate  \n",
       "0  3.363634e-06   3.018314e-08  \n",
       "1  6.389118e-20   9.448417e-21  \n",
       "2  7.259658e-23   6.353883e-38  \n",
       "3  7.297767e-04   5.367645e-06  \n",
       "4  1.588704e-02   1.861962e-03  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.concat([id_test, pd.DataFrame(Y_test_prob, columns=toxic_classes)], axis=1)\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv('../results/m000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
