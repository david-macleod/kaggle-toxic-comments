{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving M000 (log loss: 0.320) by changing MultinomialNB hyperparameters / vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from __future__ import division, print_function \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import binarize \n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from evaluation import cross_validate_multilabel, multilabel_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes and load test/train data, some input text is \"N/A\" so turn na_filter off to prevent this being converted to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_classes = [\n",
    "    'toxic', 'severe_toxic', 'obscene', \n",
    "    'threat', 'insult', 'identity_hate' \n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', na_filter=False)\n",
    "X_text = df['comment_text'].values\n",
    "Y = df[toxic_classes].values\n",
    "ids = df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Feature reduction\n",
    "To improve our model accuracy we will first try reducing the number of features.\n",
    "\n",
    "Each feature is a single token (word) found within the training data, the feature value is the count of that token within the  document record, i.e. how many times a word appeared in a particular comment\n",
    "\n",
    "The majority of these words will not be useful in making predictions, and whilst these non-discriminative features should affect each class equally, their inclusion can still result in negative performance.\n",
    "\n",
    "#### [1a] Drop low frequency tokens\n",
    "First we will remove words that only appear in a small number of documents, as their class conditional probabilities will be less reliable.\n",
    "\n",
    "Plotting histogram showing the token frequency distribution (x-axis: number of documents that token appears in, y-axis: number of tokens with given document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = CountVectorizer(binary=True).fit_transform(X_text) # binarize features for easy histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGmfQS1Lj/g9o90e0kPhhmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4c4d38590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_frequency = np.asarray(X.sum(axis=0)).flatten()\n",
    "plt.hist(document_frequency, bins=1000)\n",
    "plt.yscale('log') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite clear that the mast majority of features only appear in a small number of documents (~1) so we will model performance when setting a minimum document frequency (expressed as an integer document count). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1 | number of features: 139171\n",
      "min_df: 10 | number of features: 16887\n",
      "min_df: 100 | number of features: 3806\n",
      "min_df: 1000 | number of features: 584\n",
      "min_df: 5000 | number of features: 114\n",
      "min_df: 10000 | number of features: 59\n",
      "min_df: 20000 | number of features: 21\n",
      "min_df: 30000 | number of features: 12\n",
      "min_df: 40000 | number of features: 7\n",
      "min_df: 50000 | number of features: 2\n",
      "min_df: 60000 | number of features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531283</td>\n",
       "      <td>-0.183396</td>\n",
       "      <td>-0.419440</td>\n",
       "      <td>-0.118345</td>\n",
       "      <td>-0.450686</td>\n",
       "      <td>-0.222666</td>\n",
       "      <td>-0.320969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.354726</td>\n",
       "      <td>-0.174885</td>\n",
       "      <td>-0.280497</td>\n",
       "      <td>-0.099457</td>\n",
       "      <td>-0.302653</td>\n",
       "      <td>-0.186829</td>\n",
       "      <td>-0.233174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.347482</td>\n",
       "      <td>-0.165190</td>\n",
       "      <td>-0.256993</td>\n",
       "      <td>-0.100824</td>\n",
       "      <td>-0.284395</td>\n",
       "      <td>-0.180571</td>\n",
       "      <td>-0.222576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-0.384808</td>\n",
       "      <td>-0.115726</td>\n",
       "      <td>-0.266404</td>\n",
       "      <td>-0.094421</td>\n",
       "      <td>-0.269721</td>\n",
       "      <td>-0.171468</td>\n",
       "      <td>-0.217091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>-0.398170</td>\n",
       "      <td>-0.095440</td>\n",
       "      <td>-0.315994</td>\n",
       "      <td>-0.063098</td>\n",
       "      <td>-0.278725</td>\n",
       "      <td>-0.114721</td>\n",
       "      <td>-0.211024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>-0.397452</td>\n",
       "      <td>-0.092945</td>\n",
       "      <td>-0.308322</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>-0.268064</td>\n",
       "      <td>-0.105127</td>\n",
       "      <td>-0.205837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>-0.389652</td>\n",
       "      <td>-0.084509</td>\n",
       "      <td>-0.286901</td>\n",
       "      <td>-0.069324</td>\n",
       "      <td>-0.253020</td>\n",
       "      <td>-0.085160</td>\n",
       "      <td>-0.194761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>-0.364791</td>\n",
       "      <td>-0.081422</td>\n",
       "      <td>-0.260458</td>\n",
       "      <td>-0.055465</td>\n",
       "      <td>-0.234750</td>\n",
       "      <td>-0.076341</td>\n",
       "      <td>-0.178871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>-0.364106</td>\n",
       "      <td>-0.085165</td>\n",
       "      <td>-0.259859</td>\n",
       "      <td>-0.058536</td>\n",
       "      <td>-0.235436</td>\n",
       "      <td>-0.077088</td>\n",
       "      <td>-0.180032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>-0.318343</td>\n",
       "      <td>-0.057384</td>\n",
       "      <td>-0.208724</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>-0.198619</td>\n",
       "      <td>-0.049654</td>\n",
       "      <td>-0.142814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>-0.317029</td>\n",
       "      <td>-0.056312</td>\n",
       "      <td>-0.208124</td>\n",
       "      <td>-0.021474</td>\n",
       "      <td>-0.197668</td>\n",
       "      <td>-0.048953</td>\n",
       "      <td>-0.141593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "1     -0.531283     -0.183396 -0.419440 -0.118345 -0.450686      -0.222666   \n",
       "10    -0.354726     -0.174885 -0.280497 -0.099457 -0.302653      -0.186829   \n",
       "100   -0.347482     -0.165190 -0.256993 -0.100824 -0.284395      -0.180571   \n",
       "1000  -0.384808     -0.115726 -0.266404 -0.094421 -0.269721      -0.171468   \n",
       "5000  -0.398170     -0.095440 -0.315994 -0.063098 -0.278725      -0.114721   \n",
       "10000 -0.397452     -0.092945 -0.308322 -0.063111 -0.268064      -0.105127   \n",
       "20000 -0.389652     -0.084509 -0.286901 -0.069324 -0.253020      -0.085160   \n",
       "30000 -0.364791     -0.081422 -0.260458 -0.055465 -0.234750      -0.076341   \n",
       "40000 -0.364106     -0.085165 -0.259859 -0.058536 -0.235436      -0.077088   \n",
       "50000 -0.318343     -0.057384 -0.208724 -0.024162 -0.198619      -0.049654   \n",
       "60000 -0.317029     -0.056312 -0.208124 -0.021474 -0.197668      -0.048953   \n",
       "\n",
       "            all  \n",
       "1     -0.320969  \n",
       "10    -0.233174  \n",
       "100   -0.222576  \n",
       "1000  -0.217091  \n",
       "5000  -0.211024  \n",
       "10000 -0.205837  \n",
       "20000 -0.194761  \n",
       "30000 -0.178871  \n",
       "40000 -0.180032  \n",
       "50000 -0.142814  \n",
       "60000 -0.141593  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "min_dfs = [1, 10, 100, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 60000]\n",
    "\n",
    "for min_df in min_dfs:\n",
    "    cvec = CountVectorizer(min_df=min_df)\n",
    "    X = cvec.fit_transform(X_text)\n",
    "    cv_scores = cross_validate_multilabel(MultinomialNB(), X, Y, cv=10, scoring='neg_log_loss') \n",
    "    results.append(list(cv_scores))\n",
    "    print('min_df:', min_df, '|', 'number of features:', len(cvec.vocabulary_))\n",
    "    \n",
    "multilabel_results(results, toxic_classes, min_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, our best result comes from the model which has features with a minumum document frequent of 60,000. In this model we only have one feature..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'the': 0}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(min_df=60000)\n",
    "X = cvec.fit_transform(X_text) \n",
    "cvec.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token 'the' is unlikely to discrimate between classes, as it is so common. The most likely explanation here is that we are simply getting a \"null\" model which has a probability equal to the class prior: the likelihood of observing an example  in a class (class marginal probability)\n",
    "\n",
    "In other words for models with only very frequent, in the Bayes numerator `P(x|y)P(y)` then `P(x|y)` will be `~P(x)` (essentially independant of class) and the so `P(y)` will become the dominant term.\n",
    "\n",
    "Our single feature model goes one step further and `P(x|y)` = 1 for both classes (sum of feature / sum of all features = 1) and so we should get a constant probability for all records (equal to the class prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X, Y[:, 0])\n",
    "probs = mnb.predict_proba(X)[:,1]\n",
    "probs.min() == probs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the proportion of records which have each class attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09636832,  0.01006771,  0.05330148,  0.00318202,  0.04971257,\n",
       "        0.00849235])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sum(axis=0) / Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are dealing with very imbalanced classes, and in our class specific (one vs rest) models the class prior for the negative case will always dominate. We are essentially just prediction \"not toxic\"\" for every record and getting the best result because \"not toxic\" and getting a *good* result because that is the most likely class.\n",
    "\n",
    "This model be our new baseline (log_loss: **0.141**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1b] Select \"best\" features\n",
    "\n",
    "Rather than dropping features which have a low rate of occurence, we will try to select the features which will best discriminate between classes prior to fitting the model.\n",
    "\n",
    "We use a chi2 test for independance which compares the joint probability `P(x|y)` with `P(x)` and ranks the features which have the highest different between the conditional and marginal probabilities.\n",
    "\n",
    "For example if:\n",
    "* `P('idiot')` = 0.1 and `P('idiot'|'toxic')` = 0.6\n",
    "* `P('dog')` = 0.01 and `P('idiot'|'toxic')` = 0.15<br>\n",
    "\n",
    "Then **idiot** will have a larger chi2 value.\n",
    "\n",
    "(The actual chi2 calculation actually considers an average across all combinations of `P('idiot'|'toxic'), P('idiot'|'not_toxic'), P('not_idiot'|'toxic'), P('not_idiot'|'not_toxic')`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def kbest_feature_names(class_labels, kbest_per_class, cvec):\n",
    "    # finding names of top kbest features\n",
    "    kbest_features = defaultdict(list) \n",
    "    for toxic_class, kbest in zip(class_labels, kbest_per_class):\n",
    "        indices = kbest.get_support(indices=True)\n",
    "        scores = kbest.scores_\n",
    "        sorted_indices = [index for index, score in sorted(zip(indices, scores), key=lambda x: x[1])]  \n",
    "        for index in sorted_indices:\n",
    "            kbest_features[toxic_class].append(cvec.get_feature_names()[index])   \n",
    "            \n",
    "    return pd.DataFrame(kbest_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "X = cvec.fit_transform(X_text)\n",
    "kbest_per_class = [SelectKBest(chi2, k=15).fit(X, y) for y in Y.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting any models here are the top features per class according to chi2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>centraliststupid</td>\n",
       "      <td>fat</td>\n",
       "      <td>cunt</td>\n",
       "      <td>cunt</td>\n",
       "      <td>edie</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fat</td>\n",
       "      <td>fucking</td>\n",
       "      <td>faggot</td>\n",
       "      <td>fuck</td>\n",
       "      <td>kill</td>\n",
       "      <td>fucking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gay</td>\n",
       "      <td>hate</td>\n",
       "      <td>fat</td>\n",
       "      <td>fucking</td>\n",
       "      <td>lifetime</td>\n",
       "      <td>nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jew</td>\n",
       "      <td>jew</td>\n",
       "      <td>fuck</td>\n",
       "      <td>kill</td>\n",
       "      <td>murder</td>\n",
       "      <td>penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>licker</td>\n",
       "      <td>moron</td>\n",
       "      <td>fucking</td>\n",
       "      <td>mexicans</td>\n",
       "      <td>rvv</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mexicans</td>\n",
       "      <td>nigger</td>\n",
       "      <td>nigger</td>\n",
       "      <td>niggas</td>\n",
       "      <td>supertr0ll</td>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>niggas</td>\n",
       "      <td>suck</td>\n",
       "      <td>penis</td>\n",
       "      <td>offfuck</td>\n",
       "      <td>the_real_stephen_hawkinghttp</td>\n",
       "      <td>suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nigger</td>\n",
       "      <td>twat</td>\n",
       "      <td>shit</td>\n",
       "      <td>shit</td>\n",
       "      <td>wales</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>niggers</td>\n",
       "      <td>you</td>\n",
       "      <td>suck</td>\n",
       "      <td>suck</td>\n",
       "      <td>wanta</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tommy2010</td>\n",
       "      <td>yourselfgo</td>\n",
       "      <td>yourselfgo</td>\n",
       "      <td>yourselfgo</td>\n",
       "      <td>youcaltlas</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>die</td>\n",
       "      <td>fuck</td>\n",
       "      <td>dick</td>\n",
       "      <td>die</td>\n",
       "      <td>jim</td>\n",
       "      <td>bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bleachanhero</td>\n",
       "      <td>cunt</td>\n",
       "      <td>bullshit</td>\n",
       "      <td>bitches</td>\n",
       "      <td>di</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bunksteve</td>\n",
       "      <td>dick</td>\n",
       "      <td>cock</td>\n",
       "      <td>ass</td>\n",
       "      <td>butthead</td>\n",
       "      <td>cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ancestryfuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>ass</td>\n",
       "      <td>cock</td>\n",
       "      <td>ass</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1967</td>\n",
       "      <td>bitch</td>\n",
       "      <td>bitch</td>\n",
       "      <td>bitch</td>\n",
       "      <td>die</td>\n",
       "      <td>bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       identity_hate      insult     obscene severe_toxic  \\\n",
       "0   centraliststupid         fat        cunt         cunt   \n",
       "1                fat     fucking      faggot         fuck   \n",
       "2                gay        hate         fat      fucking   \n",
       "3                jew         jew        fuck         kill   \n",
       "4             licker       moron     fucking     mexicans   \n",
       "5           mexicans      nigger      nigger       niggas   \n",
       "6             niggas        suck       penis      offfuck   \n",
       "7             nigger        twat        shit         shit   \n",
       "8            niggers         you        suck         suck   \n",
       "9          tommy2010  yourselfgo  yourselfgo   yourselfgo   \n",
       "10               die        fuck        dick          die   \n",
       "11      bleachanhero        cunt    bullshit      bitches   \n",
       "12         bunksteve        dick        cock          ass   \n",
       "13      ancestryfuck         ass         ass         cock   \n",
       "14              1967       bitch       bitch        bitch   \n",
       "\n",
       "                          threat    toxic  \n",
       "0                           edie     fuck  \n",
       "1                           kill  fucking  \n",
       "2                       lifetime   nigger  \n",
       "3                         murder    penis  \n",
       "4                            rvv      pig  \n",
       "5                     supertr0ll     shit  \n",
       "6   the_real_stephen_hawkinghttp     suck  \n",
       "7                          wales      the  \n",
       "8                          wanta      you  \n",
       "9                     youcaltlas      fat  \n",
       "10                           jim    bitch  \n",
       "11                            di      die  \n",
       "12                      butthead     cunt  \n",
       "13                           ass      ass  \n",
       "14                           die     bark  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_feature_names(toxic_classes, kbest_per_class, cvec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these results seem logical and are tokens you would normally associate with toxic comments, however we are getting a few spurious results likely caused by low frequency tokens so we will rerun using a small cut-off for rare tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(min_df=10)\n",
    "X = cvec.fit_transform(X_text)\n",
    "kbest_per_class = [SelectKBest(chi2, k=15).fit(X, y) for y in Y.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gay</td>\n",
       "      <td>dick</td>\n",
       "      <td>cock</td>\n",
       "      <td>bitches</td>\n",
       "      <td>ass</td>\n",
       "      <td>cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>suck</td>\n",
       "      <td>ban</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suck</td>\n",
       "      <td>suck</td>\n",
       "      <td>fuck</td>\n",
       "      <td>mexicans</td>\n",
       "      <td>will</td>\n",
       "      <td>suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nigger</td>\n",
       "      <td>cunt</td>\n",
       "      <td>shit</td>\n",
       "      <td>anal</td>\n",
       "      <td>420</td>\n",
       "      <td>nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cunt</td>\n",
       "      <td>hate</td>\n",
       "      <td>bullshit</td>\n",
       "      <td>fuck</td>\n",
       "      <td>pathetic</td>\n",
       "      <td>bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>niggers</td>\n",
       "      <td>jew</td>\n",
       "      <td>fucking</td>\n",
       "      <td>bitch</td>\n",
       "      <td>bail</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mexicans</td>\n",
       "      <td>fat</td>\n",
       "      <td>penis</td>\n",
       "      <td>cocksucker</td>\n",
       "      <td>fuckin</td>\n",
       "      <td>fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jew</td>\n",
       "      <td>twat</td>\n",
       "      <td>dick</td>\n",
       "      <td>die</td>\n",
       "      <td>lifetime</td>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fuck</td>\n",
       "      <td>moron</td>\n",
       "      <td>ass</td>\n",
       "      <td>shit</td>\n",
       "      <td>jim</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>licker</td>\n",
       "      <td>nigger</td>\n",
       "      <td>cunt</td>\n",
       "      <td>kill</td>\n",
       "      <td>wales</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>faggot</td>\n",
       "      <td>ass</td>\n",
       "      <td>faggot</td>\n",
       "      <td>cock</td>\n",
       "      <td>murder</td>\n",
       "      <td>penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fat</td>\n",
       "      <td>fucking</td>\n",
       "      <td>suck</td>\n",
       "      <td>fucking</td>\n",
       "      <td>die</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chink</td>\n",
       "      <td>fuck</td>\n",
       "      <td>fat</td>\n",
       "      <td>cunt</td>\n",
       "      <td>forever</td>\n",
       "      <td>fucking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drink</td>\n",
       "      <td>faggot</td>\n",
       "      <td>nigger</td>\n",
       "      <td>fucker</td>\n",
       "      <td>di</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1967</td>\n",
       "      <td>bitch</td>\n",
       "      <td>bitch</td>\n",
       "      <td>ass</td>\n",
       "      <td>kill</td>\n",
       "      <td>bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity_hate   insult   obscene severe_toxic    threat    toxic\n",
       "0            gay     dick      cock      bitches       ass     cunt\n",
       "1            die      you       you         suck       ban      you\n",
       "2           suck     suck      fuck     mexicans      will     suck\n",
       "3         nigger     cunt      shit         anal       420   nigger\n",
       "4           cunt     hate  bullshit         fuck  pathetic    bitch\n",
       "5        niggers      jew   fucking        bitch      bail      the\n",
       "6       mexicans      fat     penis   cocksucker    fuckin      fat\n",
       "7            jew     twat      dick          die  lifetime     shit\n",
       "8           fuck    moron       ass         shit       jim      die\n",
       "9         licker   nigger      cunt         kill     wales      ass\n",
       "10        faggot      ass    faggot         cock    murder    penis\n",
       "11           fat  fucking      suck      fucking       die     fuck\n",
       "12         chink     fuck       fat         cunt   forever  fucking\n",
       "13         drink   faggot    nigger       fucker        di      pig\n",
       "14          1967    bitch     bitch          ass      kill     bark"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_feature_names(toxic_classes, kbest_per_class, cvec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look more robust. Whilst we see some of the same tokens being the best feature for multiple classes, there does seem to be a general theme in most cases. For example most of the top features in \"identity_hate\" target ethnicity / orientation etc. \n",
    "\n",
    "Will now try fitting models with only k best features retained, note that chi2 will be calculated within the cross-validation folds to avoid information from the full set leaking into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kbest_pipeline(k, classifier):\n",
    "    return Pipeline([\n",
    "        ('kbest', SelectKBest(chi2, k=k)),\n",
    "        ('classifier', classifier) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbest: 1\n",
      "kbest: 5\n",
      "kbest: 10\n",
      "kbest: 20\n",
      "kbest: 30\n",
      "kbest: 40\n",
      "kbest: 50\n",
      "kbest: 60\n",
      "kbest: 70\n",
      "kbest: 80\n",
      "kbest: 90\n",
      "kbest: 100\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "kbest = [1,5,10,20,30,40,50,60,70,80,90,100]\n",
    "cvec = CountVectorizer(min_df=10)\n",
    "X = cvec.fit_transform(X_text)\n",
    "\n",
    "for k in kbest:\n",
    "    cv_scores = cross_validate_multilabel(kbest_pipeline(k, MultinomialNB()), X, Y, cv=10, scoring='neg_log_loss') \n",
    "    results.append(list(cv_scores))\n",
    "    print('kbest:', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.317029</td>\n",
       "      <td>-0.056312</td>\n",
       "      <td>-0.208124</td>\n",
       "      <td>-0.021474</td>\n",
       "      <td>-0.197668</td>\n",
       "      <td>-0.048953</td>\n",
       "      <td>-0.141593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.317998</td>\n",
       "      <td>-0.055808</td>\n",
       "      <td>-0.192579</td>\n",
       "      <td>-0.022700</td>\n",
       "      <td>-0.197841</td>\n",
       "      <td>-0.050711</td>\n",
       "      <td>-0.139606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.305979</td>\n",
       "      <td>-0.059415</td>\n",
       "      <td>-0.180888</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.186421</td>\n",
       "      <td>-0.051306</td>\n",
       "      <td>-0.134557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.264281</td>\n",
       "      <td>-0.062739</td>\n",
       "      <td>-0.149942</td>\n",
       "      <td>-0.025550</td>\n",
       "      <td>-0.183395</td>\n",
       "      <td>-0.055534</td>\n",
       "      <td>-0.123574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.261351</td>\n",
       "      <td>-0.068612</td>\n",
       "      <td>-0.131687</td>\n",
       "      <td>-0.033252</td>\n",
       "      <td>-0.163661</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>-0.119437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.267132</td>\n",
       "      <td>-0.070520</td>\n",
       "      <td>-0.133580</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.163427</td>\n",
       "      <td>-0.069456</td>\n",
       "      <td>-0.123194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.274250</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>-0.140179</td>\n",
       "      <td>-0.039704</td>\n",
       "      <td>-0.164385</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>-0.128196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.277846</td>\n",
       "      <td>-0.072106</td>\n",
       "      <td>-0.144533</td>\n",
       "      <td>-0.047578</td>\n",
       "      <td>-0.175228</td>\n",
       "      <td>-0.087153</td>\n",
       "      <td>-0.134074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.280174</td>\n",
       "      <td>-0.073870</td>\n",
       "      <td>-0.146571</td>\n",
       "      <td>-0.051935</td>\n",
       "      <td>-0.178308</td>\n",
       "      <td>-0.093336</td>\n",
       "      <td>-0.137365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.282748</td>\n",
       "      <td>-0.075114</td>\n",
       "      <td>-0.150846</td>\n",
       "      <td>-0.056728</td>\n",
       "      <td>-0.182416</td>\n",
       "      <td>-0.098956</td>\n",
       "      <td>-0.141135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.287216</td>\n",
       "      <td>-0.077439</td>\n",
       "      <td>-0.156920</td>\n",
       "      <td>-0.059720</td>\n",
       "      <td>-0.187281</td>\n",
       "      <td>-0.102894</td>\n",
       "      <td>-0.145245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.292550</td>\n",
       "      <td>-0.087308</td>\n",
       "      <td>-0.159949</td>\n",
       "      <td>-0.062135</td>\n",
       "      <td>-0.188334</td>\n",
       "      <td>-0.107220</td>\n",
       "      <td>-0.149583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "1   -0.317029     -0.056312 -0.208124 -0.021474 -0.197668      -0.048953   \n",
       "5   -0.317998     -0.055808 -0.192579 -0.022700 -0.197841      -0.050711   \n",
       "10  -0.305979     -0.059415 -0.180888 -0.023335 -0.186421      -0.051306   \n",
       "20  -0.264281     -0.062739 -0.149942 -0.025550 -0.183395      -0.055534   \n",
       "30  -0.261351     -0.068612 -0.131687 -0.033252 -0.163661      -0.058057   \n",
       "40  -0.267132     -0.070520 -0.133580 -0.035049 -0.163427      -0.069456   \n",
       "50  -0.274250     -0.071187 -0.140179 -0.039704 -0.164385      -0.079467   \n",
       "60  -0.277846     -0.072106 -0.144533 -0.047578 -0.175228      -0.087153   \n",
       "70  -0.280174     -0.073870 -0.146571 -0.051935 -0.178308      -0.093336   \n",
       "80  -0.282748     -0.075114 -0.150846 -0.056728 -0.182416      -0.098956   \n",
       "90  -0.287216     -0.077439 -0.156920 -0.059720 -0.187281      -0.102894   \n",
       "100 -0.292550     -0.087308 -0.159949 -0.062135 -0.188334      -0.107220   \n",
       "\n",
       "          all  \n",
       "1   -0.141593  \n",
       "5   -0.139606  \n",
       "10  -0.134557  \n",
       "20  -0.123574  \n",
       "30  -0.119437  \n",
       "40  -0.123194  \n",
       "50  -0.128196  \n",
       "60  -0.134074  \n",
       "70  -0.137365  \n",
       "80  -0.141135  \n",
       "90  -0.145245  \n",
       "100 -0.149583  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_results(results, toxic_classes, kbest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst selecting top features gave us a minor improvement (k=30) the performance appears to still impacted by the class imbalance. This is most noticeable in the classes which have the smallest proportion of positive samples (e.g. identity hate) we are actually getting a worse result by adding token features to the model. \n",
    "\n",
    "This is because the class prior is most influential in these cases and will still achieve the best result by essentially assuming all cases are negative.\n",
    "\n",
    "Will try re-running the last test with uniform class priors, although will likely get a worse result as we assuming the marginal `P(yi)` = `P(not_yi)` (n.b. Using larger k values as we no longer have reliable prior) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbest: 50\n",
      "kbest: 100\n",
      "kbest: 200\n",
      "kbest: 300\n",
      "kbest: 500\n",
      "kbest: 750\n",
      "kbest: 1000\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "kbest = [50,100,200,300,500,750,1000]\n",
    "cvec = CountVectorizer(min_df=10)\n",
    "X = cvec.fit_transform(X_text)\n",
    "\n",
    "for k in kbest:\n",
    "    cv_scores = cross_validate_multilabel(kbest_pipeline(k, MultinomialNB(fit_prior=False)), X, Y, cv=10, scoring='neg_log_loss') \n",
    "    results.append(list(cv_scores))\n",
    "    print('kbest:', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.366229</td>\n",
       "      <td>-0.530969</td>\n",
       "      <td>-0.293412</td>\n",
       "      <td>-0.316796</td>\n",
       "      <td>-0.334398</td>\n",
       "      <td>-0.354402</td>\n",
       "      <td>-0.366034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.339806</td>\n",
       "      <td>-0.370090</td>\n",
       "      <td>-0.266363</td>\n",
       "      <td>-0.265583</td>\n",
       "      <td>-0.308295</td>\n",
       "      <td>-0.265856</td>\n",
       "      <td>-0.302665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.333080</td>\n",
       "      <td>-0.282233</td>\n",
       "      <td>-0.272830</td>\n",
       "      <td>-0.248829</td>\n",
       "      <td>-0.296893</td>\n",
       "      <td>-0.279281</td>\n",
       "      <td>-0.285524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.336874</td>\n",
       "      <td>-0.278493</td>\n",
       "      <td>-0.282317</td>\n",
       "      <td>-0.246813</td>\n",
       "      <td>-0.310599</td>\n",
       "      <td>-0.295175</td>\n",
       "      <td>-0.291712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.349037</td>\n",
       "      <td>-0.273103</td>\n",
       "      <td>-0.301889</td>\n",
       "      <td>-0.246370</td>\n",
       "      <td>-0.328691</td>\n",
       "      <td>-0.307564</td>\n",
       "      <td>-0.301109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>-0.361229</td>\n",
       "      <td>-0.281610</td>\n",
       "      <td>-0.315977</td>\n",
       "      <td>-0.247860</td>\n",
       "      <td>-0.341155</td>\n",
       "      <td>-0.319008</td>\n",
       "      <td>-0.311140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-0.371568</td>\n",
       "      <td>-0.286487</td>\n",
       "      <td>-0.328933</td>\n",
       "      <td>-0.250799</td>\n",
       "      <td>-0.354797</td>\n",
       "      <td>-0.324738</td>\n",
       "      <td>-0.319554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "50   -0.366229     -0.530969 -0.293412 -0.316796 -0.334398      -0.354402   \n",
       "100  -0.339806     -0.370090 -0.266363 -0.265583 -0.308295      -0.265856   \n",
       "200  -0.333080     -0.282233 -0.272830 -0.248829 -0.296893      -0.279281   \n",
       "300  -0.336874     -0.278493 -0.282317 -0.246813 -0.310599      -0.295175   \n",
       "500  -0.349037     -0.273103 -0.301889 -0.246370 -0.328691      -0.307564   \n",
       "750  -0.361229     -0.281610 -0.315977 -0.247860 -0.341155      -0.319008   \n",
       "1000 -0.371568     -0.286487 -0.328933 -0.250799 -0.354797      -0.324738   \n",
       "\n",
       "           all  \n",
       "50   -0.366034  \n",
       "100  -0.302665  \n",
       "200  -0.285524  \n",
       "300  -0.291712  \n",
       "500  -0.301109  \n",
       "750  -0.311140  \n",
       "1000 -0.319554  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_results(results, toxic_classes, kbest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected results are worse, to avoid this we need to find a way of making the class prior less influential, but not ignored completely.\n",
    "\n",
    "Will explore a different approach using a logistic regression from the a Kaggle kernel that achieved log_loss of 0.052 in notebooks d002 to see if we can identify the reason for the increased performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
