{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving m001 (log loss: 0.117) by exploring naive bayes + logistic regression approach\n",
    "Found in Jeremy Howard Kaggle kernel [here](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline-eda-0-052-lb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from __future__ import division, print_function \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import binarize \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from evaluation import cross_validate_multilabel, multilabel_results, log_loss_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_classes = [\n",
    "    'toxic', 'severe_toxic', 'obscene', \n",
    "    'threat', 'insult', 'identity_hate' \n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', na_filter=False)\n",
    "X_text = df['comment_text'].values\n",
    "Y = df[toxic_classes].values\n",
    "ids = df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First running the code found in the Kaggle kernel to confirm that we can replicate the log loss of 0.052. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile('([{}“”¨«»®´·º½¾¿¡§£₤‘’])'.format(string.punctuation))\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can replicate the result, but will now investigate why this gives a significantly better result than m001. An initial comparison of the differences between the two models (we will refer to the new model as **d002**) :\n",
    "* m001 uses a multinomial naive Bayes with class priors whereas d002 uses a regularized logistic regression\n",
    "* m001 features are token counts, d002 are tf-idf values (multiplied by a multinomial class conditional probability)\n",
    "* d002 uses a combination of unigrams and bigrams as features (only unigrams in m001)\n",
    "* tokenization is different between the models and accents are stripped in d002\n",
    "* chi2 explicit feature selection in m001 compared to implicit feature \"reduction\" through l2 regularization in d002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the origin approach from the **JeremyHoward** Kaggle kernel, adapted into a scikit-learn classifier by **AlexSánchez**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the paper referenced by Jeremy the motivation for this approach is that the SVM component (here a logistic regression) will perform better on longer text documents, whereas the Naive Bayes will be better on shorter snippets of text. \n",
    "\n",
    "By combining the two approaches we can increase accuracy across documents of varying length, as found here in the toxic comments dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "\n",
    "X = vec.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbsvm = NbSvmClassifier(C=4, dual=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = OneVsRestClassifier(nbsvm) \n",
    "models.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_prob = models.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05314303268580043"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_multilabel(Y_test, Y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can replicate the increased performance recorded in the original notebook. This approach is just an ('l2') regularized logistic regression which uses tf-idf values as features, with an additional multiplication by the multinomial naive bayes probability (used as a prior probability in the notebook).\n",
    "\n",
    "Next we will investigate how much benefit is gained from using this \"multinomial prior\" vs. tf-idf values alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_clf'])\n",
    "        return self._clf.predict(x) \n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_clf'])\n",
    "        return self._clf.predict_proba(x) \n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=4, dual=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053508391182241773"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = OneVsRestClassifier(lr) \n",
    "models.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_prob = models.predict_proba(X_test)\n",
    "                                  \n",
    "log_loss_multilabel(Y_test, Y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can achive a very similar log_loss without the \"multinomial prior\" so will continue without this for now to keep a simpler model, without a noticeable decrease in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDATE: New train/test set released by Kaggle. Now re-evaluating models on latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_new.csv', na_filter=False)\n",
    "X_text = df['comment_text'].values\n",
    "Y = df[toxic_classes].values\n",
    "ids = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "\n",
    "X = vec.fit_transform(X_text)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052406458093759718"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbsvm = NbSvmClassifier(C=4, dual=True, n_jobs=-1)\n",
    "\n",
    "models = OneVsRestClassifier(nbsvm) \n",
    "models.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_prob = models.predict_proba(X_test)\n",
    "\n",
    "log_loss_multilabel(Y_test, Y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-running without \"multinomial prior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05196229289823228"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=4, dual=True, n_jobs=-1)\n",
    "\n",
    "models = OneVsRestClassifier(lr) \n",
    "models.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_prob = models.predict_proba(X_test)\n",
    "\n",
    "log_loss_multilabel(Y_test, Y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will now submit this latter model to leaderboard, then in the next notebook test more of the hyperparameters of the logistic regression / vectorizer to see if we can increase performance and/or decrease complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
