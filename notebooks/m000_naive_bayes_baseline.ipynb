{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple naive bayes model to get a baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from __future__ import division, print_function \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes and load test/train data, some input text is \"N/A\" so turn na_filter off to prevent this being converted to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_classes = [\n",
    "    'toxic', 'severe_toxic', 'obscene', \n",
    "    'threat', 'insult', 'identity_hate' \n",
    "]\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', na_filter=False)\n",
    "# single column containing comment strings \n",
    "X_train_text = df['comment_text'].values\n",
    "# matrix of shape (n_sample, n_classes) containing class indicator variables \n",
    "Y_train = df[toxic_classes].values\n",
    "id_train = df['id']\n",
    "\n",
    "df = pd.read_csv('../data/test.csv', na_filter=False)\n",
    "X_test_text = df['comment_text'].values\n",
    "id_test = df['id']\n",
    "\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building sparse features matrices (one column per token). Using pre-fitted vectorizer on test data to ensure features are the same as training data. \n",
    "\n",
    "It is clear why we would need our two sparse matrices to allign, but regardless of this we would want to exclude features not seen in training data anyway. Whilst we would not get probabilities for these extra features, they _would_ contribute to the denominator of the multinomial `P(xi|yi)` calculation and so affect other \"live\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 139171\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer()\n",
    "X_train = cvec.fit_transform(X_train_text)\n",
    "X_test = cvec.transform(X_test_text)\n",
    "\n",
    "del(X_train_text)\n",
    "del(X_test_text)\n",
    "\n",
    "print('number of features:', len(cvec.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_multilabel(model, X, Y, **cv_kwargs):\n",
    "    \"\"\"cross validation for a multi-label target\"\"\"\n",
    "    # scores is ndarray of shape (number of Y classes, number of cross validation folds)\n",
    "    scores_per_class = np.array([cross_val_score(model, X, y, **cv_kwargs) for y in Y.T])\n",
    "    # return average score across folds, for each class\n",
    "    return scores_per_class.mean(axis=1)\n",
    "\n",
    "def multilabel_results(cv_scores, class_labels, aggregate=True, index=None):\n",
    "    df = pd.DataFrame([cv_scores], columns=class_labels, index=index)\n",
    "    if aggregate:\n",
    "        df['all'] = df.mean(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation for competition is mean of the log loss across all classes. Computing metric across 10 folds to give us our baseline score\n",
    "\n",
    "N.B. folds will be different for each class (model) as stratified is default. In future would be preferable to find a way to stratify across all classes to ensure averaged log_loss is across models trained on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.531283</td>\n",
       "      <td>-0.183396</td>\n",
       "      <td>-0.41944</td>\n",
       "      <td>-0.118345</td>\n",
       "      <td>-0.450686</td>\n",
       "      <td>-0.222666</td>\n",
       "      <td>-0.320969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic  obscene    threat    insult  identity_hate  \\\n",
       "0 -0.531283     -0.183396 -0.41944 -0.118345 -0.450686      -0.222666   \n",
       "\n",
       "        all  \n",
       "0 -0.320969  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_validate_multilabel(MultinomialNB(), X_train, Y_train, cv=10, scoring='neg_log_loss')\n",
    "multilabel_results(cv_scores, toxic_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting models on all data, then applying to test data to give us our probabilities for submission\n",
    "\n",
    "We use OneVsRestClassifier to fit one model per class as MultinomialNB cannot handle a multi-label input by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "ovr_nb = OneVsRestClassifier(nb_model)\n",
    "ovr_nb.fit(X_train, Y_train) \n",
    "ovr_nb.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.78686108e-005,   1.90288426e-011,   5.72171323e-006,\n",
       "          3.47230459e-012,   1.21433115e-006,   1.63990509e-009],\n",
       "       [  8.11093685e-030,   2.61409997e-083,   3.94468214e-039,\n",
       "          1.49574877e-099,   1.26741258e-044,   1.55645858e-073],\n",
       "       [  4.40003800e-029,   6.16082809e-082,   7.82543846e-038,\n",
       "          1.07465287e-098,   2.06179104e-040,   5.31569640e-080],\n",
       "       ..., \n",
       "       [  1.04167968e-006,   5.83827617e-013,   1.64828968e-007,\n",
       "          1.34969600e-014,   7.39746231e-008,   6.53275870e-012],\n",
       "       [  5.72750836e-003,   4.33806004e-004,   5.94946763e-003,\n",
       "          1.01509543e-004,   4.55276950e-003,   1.10152721e-003],\n",
       "       [  1.34294945e-040,   1.56448653e-130,   3.23802221e-055,\n",
       "          8.54112961e-168,   2.05750382e-061,   6.77445083e-127]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_prob = ovr_nb.predict_proba(X_test)\n",
    "Y_test_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that predict_proba function returns the normalised probabilities over each one-vs-rest class distribution.\n",
    "\n",
    "In other words, we don't use the raw \"posterior\" probability calculated by the MultinomialNB `P(x|y)•P(y)`  as these values will be very small, and is not a realistic probability anyway as this does not include the \"evidence\" term P(x) in the Bayes equation as this is fixed for all classes. Instead this value is normalised so that the \"probabilities\" for each record sum to ~1 within each binary class decision. So the probability `P(yi|Xi) + P(not(yi)|Xi) ≈ 1`.\n",
    "\n",
    "Note that as this is a multilabel classification for the one-vs-rest estimator the probability  is normalised within each class, and not across _all_ classes, so the sum of all probabilities across all classes does not have to sum to 1. For example we can have `P(y1|xi) = P(y2|xi) ≈ 1`  etc which gives us a high probability of that record belonging to multiple classes. Equally it is valid for the probability of a record to have low probabilities across all classes, suggesting it does not belong to any of the classes (we have many training examples that exhibit this characteristic). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>1.786861e-05</td>\n",
       "      <td>1.902884e-11</td>\n",
       "      <td>5.721713e-06</td>\n",
       "      <td>3.472305e-12</td>\n",
       "      <td>1.214331e-06</td>\n",
       "      <td>1.639905e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>8.110937e-30</td>\n",
       "      <td>2.614100e-83</td>\n",
       "      <td>3.944682e-39</td>\n",
       "      <td>1.495749e-99</td>\n",
       "      <td>1.267413e-44</td>\n",
       "      <td>1.556459e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>4.400038e-29</td>\n",
       "      <td>6.160828e-82</td>\n",
       "      <td>7.825438e-38</td>\n",
       "      <td>1.074653e-98</td>\n",
       "      <td>2.061791e-40</td>\n",
       "      <td>5.315696e-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>1.447875e-02</td>\n",
       "      <td>1.218987e-07</td>\n",
       "      <td>5.627875e-04</td>\n",
       "      <td>7.577484e-09</td>\n",
       "      <td>2.140137e-04</td>\n",
       "      <td>2.541342e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>2.433156e-02</td>\n",
       "      <td>2.481446e-03</td>\n",
       "      <td>1.626303e-02</td>\n",
       "      <td>1.194813e-03</td>\n",
       "      <td>1.136432e-02</td>\n",
       "      <td>7.060328e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         toxic  severe_toxic       obscene        threat  \\\n",
       "0   6044863  1.786861e-05  1.902884e-11  5.721713e-06  3.472305e-12   \n",
       "1   6102620  8.110937e-30  2.614100e-83  3.944682e-39  1.495749e-99   \n",
       "2  14563293  4.400038e-29  6.160828e-82  7.825438e-38  1.074653e-98   \n",
       "3  21086297  1.447875e-02  1.218987e-07  5.627875e-04  7.577484e-09   \n",
       "4  22982444  2.433156e-02  2.481446e-03  1.626303e-02  1.194813e-03   \n",
       "\n",
       "         insult  identity_hate  \n",
       "0  1.214331e-06   1.639905e-09  \n",
       "1  1.267413e-44   1.556459e-73  \n",
       "2  2.061791e-40   5.315696e-80  \n",
       "3  2.140137e-04   2.541342e-08  \n",
       "4  1.136432e-02   7.060328e-04  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.concat([id_test, pd.DataFrame(Y_test_prob, columns=toxic_classes)], axis=1)\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv('../results/m000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
